# SPECT平片降噪思路笔记 (AI整理版)

## 问题1: 如何处理目标图像本身带噪声的问题？

**用户提议**:
我有一个想法，假设我现在在做unet降噪，我的输入配对图像是一个spect平片，重采样得到的低质量图片，这一对。但是这样的话，其实我的target本身就是有噪声的，我觉得不是一个金标准，我能不能用模拟数据训练一个从正常剂量到groundtruth，然后用这个模型将正常剂量输出一下，再用这个和低剂量配对，训练一个网络？

**AI回答**:
这是一个非常有洞察力的两阶段训练思路，在缺乏完美"金标准"的情况下是合理且创新的。

*   **阶段一：利用模拟数据训练一个"理想去噪器" (Model_A)**
    *   **数据**:
        *   输入: 模拟的正常剂量图像。
        *   目标: 对应的绝对无噪声、高质量的模拟 Ground Truth (GT)。
    *   **目的**: 训练网络 (如 U-Net) 从模拟正常剂量图像中恢复出 GT。

*   **阶段二：利用阶段一的输出作为更优的 Target，训练针对低剂量数据的去噪器 (Model_B)**
    *   **生成更优的 Target**:
        *   输入: 真实的"正常剂量 SPECT 平片"。
        *   处理: 将这些真实正常剂量图像输入到 Model_A 中。
        *   输出: Model_A 的输出，称为"伪金标准 (Pseudo_GT)"，理论上比原始正常剂量图像更接近无噪声状态。
    *   **模型训练**:
        *   输入: 通过重采样真实正常剂量图像得到的"低质量/低剂量图像"。
        *   目标: 对应的 Pseudo_GT。
        *   目的**: 训练新网络从低剂量图像恢复出更高质量的 Pseudo_GT。

*   **此方法的优点**:
    1.  **提升 Target 质量**: 试图得到比原始有噪数据更接近"真实干净"状态的中间目标。
    2.  **利用模拟数据的理想性**: 模拟数据可以提供完美的 Ground Truth。
    3.  **桥接模拟与真实**: Model_A 将模拟数据学到的理想去噪能力尝试迁移到真实数据上。
    4.  **更聚焦于低剂量降噪**: Model_B 专门针对从低剂量到"伪金标准"的转换。
    5.  **减少对完美金标准的依赖**: 最终模型不再直接依赖难以获取的真实完美金标准。

*   **潜在的考虑点和挑战**:
    *   **模拟数据的真实性 (Domain Gap)**: Model_A 的性能高度依赖于模拟数据的逼真程度。若模拟与真实差异过大，Model_A 处理真实图像时可能效果不佳或引入伪影。
    *   **误差累积**: 若 Model_A 去噪不完美，其产生的 Pseudo_GT 会包含残余噪声或伪影，Model_B 会将这些不完美也作为学习目标。
    *   **模型容量和训练稳定性**: 两阶段均需仔细设计。
    *   **评估的复杂性**: 最终评估 Model_B 时，可能需要无参考指标或医生盲评。

*   **结论与关键**:
    *   想法很好，是富有创造性的策略。
    *   **关键在于**: 尽可能提高模拟数据的逼真度；仔细评估 Model_A 在真实正常剂量数据上的表现。

---

## 问题2: U-Net 中编码器和解码器的作用是什么？如何用于域适应？

**AI回答**:

*   **Encoder (下采样部分)**:
    *   通过卷积和池化层逐步扩大感受野，丢掉精细纹理，保留抽象语义特征。
    *   最底层的 bottleneck 特征最"语义化"，与图像分布/噪声分布最相关。
    *   **应用**: 如果想做"域不变特征"，一般把 encoder 视为 **feature extractor**。

*   **Decoder (上采样部分)**:
    *   负责把抽象特征还原到像素域。
    *   重建质量、细节锐度主要靠 decoder 和 skip-connection 中的浅层特征。
    *   **应用**: decoder 视为 **域内的重建器**。

---

## 问题3: 基于上述思路，如何设计一个可发表的创新降噪框架？

**AI回答**:
提出 **Dual-Head U-Net + Domain Alignment** 方案。

*   **可用数据类型 (示例)**:
    *   SimL (低计数模拟), SimH (高计数模拟), SimI (理想模拟)
    *   RealL (低计数真实), RealH (高计数真实)
*   **目标**: 从 RealL 输入，输出 RealH 级别的降噪效果，并尽量逼近 SimI 的视觉质量。

*   **网络结构**:
    *   **共享 Encoder**: 学习"域不变"的特征。
    *   **两个 Decoder/Head**:
        *   **Head-H (High-count like)**: 负责恢复"可获得的"高计数图像。监督信号来自 SimH (模拟域) 或 RealH (真实域，若有)。
        *   **Head-I (Ideal-like)**: 负责在模拟域上向理想图像 (SimI) 逼近。训练时只对 Sim 数据使用 SimI 作为监督信号。

*   **训练顺序与策略**:
    1.  **阶段①: 源域 (模拟域) 全监督预训练**:
        *   `Loss_Sim = L1(Head-H(SimL), SimH) + λ * L1(Head-I(SimL), SimI)`
        *   (λ为权重系数)
    2.  **阶段②: 无监督域对齐 (UDA) - 连接模拟域与真实域**:
        *   **A) 特征级对抗**: 引入判别器 D，用于区分 `Encoder(SimL)` 和 `Encoder(RealL)` 输出的特征。Encoder 的目标是欺骗判别器，从而使两域特征分布对齐。
            *   `Loss_adv = BCE(D(Encoder(SimL)), label_sim) + BCE(D(Encoder(RealL)), label_real)` (通过梯度反转层 GRL 更新 Encoder)
        *   **B) 低剂量一致性 (真实域内约束)**: 对 RealL 进行两种不同的轻微数据增强 (aug1, aug2)，要求 Head-H 对这两个增强版本的输出保持一致。
            *   `L_cons = ||Head-H(aug1(RealL)) - Head-H(aug2(RealL))||`
        *   **C) 伪标签自训练 (可选, 真实域内)**: 使用当前模型对 RealL 进行推理得到 Pseudo_H (伪高计数图像)。过滤掉极端值后，可将 (RealL, Pseudo_H) 作为额外的训练对。
            *   `L_pseudo = ||Head-H(RealL) - Pseudo_H_filtered||`
        *   **总UDA损失**: `Loss_UDA = Loss_adv + α * L_cons + β * L_pseudo` (α, β为权重)
    3.  **阶段③: 目标域 (真实域) 少量监督微调 (可选)**:
        *   如果拥有少量 RealL -> RealH 的配对数据，可以对 Head-H 进行微调。
        *   此时 Encoder 可以部分冻结或以更小的学习率更新，以防遗忘从模拟域和UDA阶段学到的知识。
        *   Head-I 在此阶段通常不再更新，或以极小的权重更新，以避免模拟数据的先验过度影响真实输出。

*   **推理阶段**:
    *   对于输入的 RealL 图像，主要使用 **Head-H** 的输出作为最终的降噪结果。
    *   Head-I 的输出可以作为一种可视化的参考，或用于后续研究的附加指标。

*   **为什么这样设计能解决顾虑?**:
    *   **Encoder 对齐**: 对抗学习和一致性约束使得模拟域和真实域的特征分布更接近，缓解 domain gap。
    *   **"双头"隔离**:
        *   Head-H 负责生成"可验证的"高计数目标图像，后期还能用真实标签微调。
        *   Head-I 只在模拟域使用理想标签，其作用是迫使共享的 Encoder 学习到更接近理想图像上界的特征表示能力。但在真实域推理时，由于不直接使用 Head-I 的输出，可以避免将模拟数据特有的伪影带到最终的真实图像结果中。

*   **可发表的创新点**:
    *   "多头监督 + 领域对抗 + 一致性自监督"的组合策略在 PET/SPECT 降噪领域尚不多见。
    *   实验部分可以进行消融研究 (ablation study)：例如去掉 Head-I / 去掉对抗 / 去掉一致性约束，通过各项指标对比，证明框架中每个组成部分的贡献。

*   **关键实验指标建议**:
    1.  **模拟测试集评估**: 使用 PSNR/SSIM 等指标，对比 Head-I(SimL) 与 SimI，以及 Head-H(SimL) 与 SimH，证明模型在模拟域的上界能力和目标达成度。
    2.  **真实验证集评估**:
        *   使用无参考图像质量评估指标如 NIQE/BRISQUE 来比较 RealL 和 Head-H(RealL) 的提升。
        *   如果存在 RealH 作为参考，计算 PSNR/SSIM。
        *   进行专家盲评 (例如，针对噪声水平、细节保留、诊断置信度等进行打分)。
    3.  **领域对齐效果证明**:
        *   使用 t-SNE 等降维方法可视化 Encoder 输出的模拟域特征和真实域特征，观察其混合程度。
        *   展示域判别器在训练过程中的准确率下降曲线。

*   **实践细节提示**:
    *   权重系数 λ、α、β 通常需要通过实验搜索 (例如从 0.1 到 0.5)。
    *   对抗训练可使用梯度反转层 (GRL)。判别器通常用几层简单的CNN即可。
    *   微调阶段学习率要小 (例如 ≤ 1e-5)，可以先冻结 Encoder 的浅层部分，训练一段时间后再解冻，以求稳定。
    *   若显存紧张，可以让两个 Head 共享一部分解码器上采样模块，只在最后几层分离。

*   **论文思路一句话总结**:
    "我们提出了一种双输出的U-Net域适应框架：利用模拟数据的双重监督（高计数模拟+理想模拟）来训练模型掌握降噪能力的上限，同时通过对抗性特征对齐和一致性约束将编码器特征域无关化，最后可选择使用少量真实标签对关键的解码器头进行微调，从而实现在真实低剂量PET/SPECT图像上优于现有方法的降噪效果。"

---

## 问题4: 能否将预测的高计数图像 (来自 Head-H) 和预测的理想图像 (来自 Head-I) 进行插值，以在应用阶段灵活调节输出效果？

**用户想法**:
希望能将预测出的高计数和预测出的理想图做一个插值，0.2 0.4 0.6这样，到最后应用阶段可以调节输出的，这样我实际用的时候，我就能输出一个更确信的图和一个更想象但是看起来效果更好的图，在实际域如此推理。虽然我评价的时候，对于更想象的图就用人工主观评判吧，因为指标上不同。

**AI回答**:
这非常好，可以实现一个"**双头输出 + 连续可调插值**"的方案，让临床医生可以根据需要在"可信-写实"与"理想-观感"之间平滑切换。

*   **网络与训练流程回顾**:
    *   基本同问题3中的 Dual-Head U-Net + Domain Alignment 框架。
    *   共享 Encoder (学习域不变特征)。
    *   Head-H: 解码器 H(·)，监督目标是 SimH / RealH。
    *   Head-I: 解码器 I(·)，监督目标是 SimI (仅在模拟域参与梯度计算)。
    *   总损失包含 L1 损失 (SimL 到 SimH/SimI) 和 UDA 对齐损失。
*   **插值推理接口**:
    1.  **前向推理**:
        *   对于输入的真实低剂量图像 `x = RealL`
        *   `y_h = Head-H(x)`  (代表"写实"风格，接近高计数图像)
        *   `y_i = Head-I(x)`  (代表"理想"风格，可能更干净、细节更锐利，但基于模拟数据)
    2.  **线性混合**:
        *   `y_output(α) = (1 - α) * y_h + α * y_i`
        *   其中 `α` 是一个从 0 到 1 的插值系数。
        *   **用户界面 (UI)**: 可以提供一个滑条让用户动态调整 `α`，或者提供几个预设的 `α` 值 (例如，α ∈ {0.0, 0.25, 0.5, 0.75, 1.0}) 作为快速切换挡位。这种逐像素加权计算非常快，实时调整基本无压力。
    3.  **理论依据**:
        *   `y_h` 的统计分布与真实高剂量图像 (`RealH`) 对齐，因此更"可靠"，减少"幻觉"。
        *   `y_i` 在模拟域学习到了理想图像的上界特征，可能表现为"更平滑、细节更锐利"。
        *   线性组合的结果 `y_output(α)` 仍然保留在由两个解码器输出张成的特征子空间内，这有助于避免产生完全未知的、离谱的伪影。
    4.  **可选高级方案：网络学习逐像素插值权重 (Soft Mask)**:
        *   可以让网络额外输出一个与图像同尺寸的权重图 `α_map = G_alpha(Encoder(x))`，其中 `G_alpha` 是一个小型的解码器分支，输出值经过 Sigmoid 归一化到 [0,1]。
        *   则混合输出为 `y_output_pixelwise = (1 - α_map) * y_h + α_map * y_i`。
        *   训练时可以对 `α_map` 加入一些正则化项，如总变分 (Total Variation, TV) 正则，使其平滑。
        *   推理时，医生仍然可以通过一个全局的 `α_global` 因子来整体调节这种混合强度: `y_final = (1 - α_global) * y_h + α_global * y_output_pixelwise` (或者直接 `y_final = (1 - α_global_overall) * y_h + α_global_overall * y_i_from_pixelwise_blend_if_α_map_is_used_as_a_modifier_to_y_i`)。
        *   这种方式可能让网络学会在图像的不同区域（如边缘 vs. 均匀区域）自动采用不同的混合权重。

*   **评价方案与论文撰写角度**:
    1.  **客观指标**:
        *   `y_h` (即 α=0 时) 与 `RealH` (如果可用) 计算 PSNR/SSIM。
        *   `y_i` (即 α=1 时) 与 `RealH` 的 PSNR/SSIM 可能会下降，但可以报告其 NIQE/BRISQUE (期望更低) 或 FID (期望更低，如果适用) 等指标，以显示"视觉质量"的某种提升或变化。
        *   绘制 **`α` 值与各项指标 (如 PSNR, NIQE) 的关系曲线**，展示不同折中点下的性能。
    2.  **主观盲评**:
        *   邀请多名核医学专家，在不知晓 `α`具体值的情况下，对不同 `α` 设置下生成的图像进行随机顺序的评估。
        *   评分维度可包括：噪声抑制程度、细节清晰度、伪影情况、诊断置信度等。
        *   使用统计检验方法 (如 Friedmann 检验 + Nemenyi test for post-hoc comparisons) 分析评分结果，看是否存在某个 `α` 区间获得了统计上显著更优的综合评价。
    3.  **安全性与可解释性讨论**:
        *   强调 `α = 0.0` (即纯 `y_h` 输出) 始终是可用的"底线"，保证了结果的"最可信"状态。
        *   可以提供一个可视化工具，显示 `y_i` 和 `y_h` 之间的局部差异热图 (`|y_i - y_h|`)，让医生能一键查看插值主要在哪些区域产生了显著变化。
    4.  **论文中的创新点表述**:
        *   "首次在 PET/SPECT 低剂量重建中提出了一种双头网络结合可控插值输出的框架，使得同一网络在推理阶段能够提供从高保真到增强视觉效果的连续、可调节的输出折中；通过客观实验与专家盲评均验证了该交互式输出策略在临床应用中的潜在价值。"

*   **实现要点 (PyTorch 伪代码示意)**:
    ```python
    # 前向传播获取两个头的输出
    # x_low_dose_real = ... # 真实低剂量输入
    # shared_features = shared_encoder(x_low_dose_real)
    # y_h = head_H(shared_features)  # (B, C, H, W), 写实输出
    # y_i = head_I(shared_features)  # (B, C, H, W), 理想化输出

    # alpha = 0.4  # 从UI读取或预设
    # y_interpolated = (1 - alpha) * y_h + alpha * y_i

    # 如果使用网络学习的alpha_map:
    # alpha_map_pred = head_alpha(shared_features) # (B, 1, H, W)
    # alpha_map_pred = torch.sigmoid(alpha_map_pred)
    # y_output_pixelwise = (1 - alpha_map_pred) * y_h + alpha_map_pred * y_i
    # global_alpha_tuning = 0.5 # 医生可调的全局因子
    # final_output = (1 - global_alpha_tuning) * y_h + global_alpha_tuning * y_output_pixelwise
    # 训练时可能对 alpha_map_pred 加 Total Variation Loss
    # loss_tv_alpha = tv_loss(alpha_map_pred)
    # total_loss += kappa * loss_tv_alpha
    ```

*   **常见疑问与解答**:
    *   **Q1: 是否会产生"虚假细节"或"幻觉"?**
        *   A: `y_i` (理想化输出) 由于仅在模拟域使用完美 SimI 监督，确实可能在真实数据上产生一些未在真实高剂量数据中得到验证的强化细节或平滑效果。
        *   **应对策略**:
            *   默认的或推荐的 `α` 值可以偏向 `y_h` (例如 `α` 初始值设为 0.3-0.5)，从而限定理想成分的占比。
            *   UI 中提供差异图 (`|y_i - y_h|`) 供医生快速核查插值的主要影响区域。
            *   在论文和产品说明中明确承认这种可能性，并强调医生应结合临床经验判断，以及始终可以回退到 `α=0` (纯 `y_h`) 的最保守模式。
    *   **Q2: 这种线性融合是不是太简单了?**
        *   A: 简单通常意味着更好的可解释性和更容易的工程部署。线性融合已经被证明在许多风格迁移和图像融合任务中能够提供平滑且有意义的过渡。
        *   在追求更高深的方法（例如使用 AdaIN-style 的逐通道特征融合，或者将 `y_h`, `y_i` 拼接后通过一个小型 1x1 Conv 网络学习融合权重）之前，线性融合因其简洁和直观，更容易被接受和验证其有效性。如果实验证明线性融合已足够提供用户期望的、在质感-噪声之间连贯的平衡，那么它就是一种实用的好方法。

*   **结论**:
    *   通过共享 Encoder 和对抗性域对齐，确保了从模拟域到真实域特征的可迁移性。
    *   双头输出设计将"客观可信的重建 (Head-H)"与"主观上可能更悦目的理想化图像 (Head-I)"进行了解耦。
    *   线性的、可调节的插值机制 (或更高级的可学习 `α_map` 结合全局滑条) 赋予了临床用户在应用端根据实际需求动态调整输出图像特性的能力。
    *   该设计不仅满足了实际使用场景的灵活性需求，也包含了足够的学术新颖性 (如可控输出、多监督源的利用、域适应策略的整合)，完全可以支撑一篇方法与应用并重的科研论文。

# 5月16日
## N2V 半监督 自监督
![image](img/半监督.png)
在**无限数据和足够模型容量**下，N2N和有监督的贝叶斯最优解相同——都是底层真信号 λ 的条件期望。
