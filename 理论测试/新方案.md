# SPECT骨平片降噪：一项基于稳定监督与统计一致性评估的新研究方案

## 1. 研究背景与核心问题

### 1.1. 医学成像的两难困境

SPECT（单光子发射计算机断层扫描）骨显像在临床诊断中发挥着重要作用，但面临一个根本性挑战：为了降低患者的辐射暴露，临床实践中往往采用低剂量扫描，这导致图像中光子计数较少，噪声严重。这种噪声的特点是统计性的泊松噪声，具有"信号越弱，噪声越强"的特性。

传统的图像去噪方法在这种复杂的噪声环境下往往表现不佳。更重要的是，我们在处理真实临床数据时，经常面临一个关键问题：**没有"完美"的参考图像（Ground Truth, GT）**，这使得如何评估去噪效果成为一个难题。

### 1.2. 现有方法的局限性

目前，大多数研究采用的评估方法存在根本性缺陷：

1. **评估指标不适用**：传统的PSNR和SSIM指标假设图像是确定性的，但SPECT成像本质上是一个随机过程。用这些指标评估随机成像的去噪效果，可能会得出误导性的结论。

2. **训练目标存在偏差**：现有方法通常直接以高计数图像作为训练目标，但这种做法忽略了一个事实：即使是高计数图像，它本身也包含噪声，并不是真正的"完美答案"。

## 2. 总体方案与核心创新

针对上述挑战，本方案提出了一种全新的研究范式，从"训练目标"和"评估体系"两个层面进行根本性革新。

![技术路线图](fig/技术路线.svg)

*   **核心创新一：重塑训练目标**：我们不再将充满随机性的HQ图像直接作为监督信号，而是提出使用一个经自监督去噪预处理的HQ图像作为更稳定、更可靠的训练目标（可视为"伪GT"）。这样做的好处是，网络可以学习逼近潜在的、无噪的基底信号，而不是去拟合随机噪声。

*   **核心创新二：重建评估体系**：我们摒弃不适用的传统指标，引入并验证两种更适合随机成像任务的评估策略：
    *   **泊松对数似然（PLL）**：从统计学角度衡量模型输出与原始高计数数据的生成过程是否一致。这个指标能够更好地反映模型是否真正理解了图像背后的物理过程。
    *   **含噪LPIPS评估方法**：设计一套可在仿真数据上验证的流程，使得LPIPS这一强大的感知度量能够被可靠地应用于没有GT的临床数据评估中。这样，我们就能在临床实践中科学地评估和比较不同的去噪算法。

通过这两点创新，本方案旨在为SPECT图像去噪提供一个更接近临床真实需求、更具可解释性、结果更可靠的解决方案。

## 3. 技术路径一：稳定监督学习范式

本方案的第一个核心，是改革深度学习网络的训练方法。

### 3.1. 传统监督方法的理论缺陷

首先，让我们从数学角度来理解这个问题。令 $X_{GT} \in \mathbb{R}^{H \times W}$ 为未知的、无噪声的理想图像（Ground Truth），它代表了组织器官对放射性示踪剂的真实吸收分布。在SPECT成像中，我们观测到的图像是光子计数的集合，其每个像素的计数值 $k$ 遵从泊松分布，其期望 $\lambda$ 等于 $X_{GT}$ 中对应位置的强度值。

因此，高计数（HQ）和低计数（LQ）图像可以分别建模为：
$$ Y_{HQ} \sim \text{Poisson}(X_{GT}) $$
$$ Y_{LQ} \sim \text{Poisson}(\alpha X_{GT}), \quad \text{其中 } 0 < \alpha < 1 $$
这里，$\alpha$ 是代表计数水平降低的尺度因子。去噪任务的目标是设计一个网络 $f_\theta$，输入 $Y_{LQ}$，输出对 $X_{GT}$ 的一个准确估计 $\hat{X}_{GT} = f_\theta(Y_{LQ})$。

传统的监督学习方法通常使用 $L_1$ 或 $L_2$ 损失函数来最小化网络输出与 $Y_{HQ}$ 之间的差异：
$$ \mathcal{L}_{trad}(\theta) = ||f_\theta(Y_{LQ}) - Y_{HQ}||_p^p $$
其中 $p$ 通常为1或2。这种方法的本质问题在于，它优化的目标是 $Y_{HQ}$，而 $Y_{HQ}$ 本身是 $X_{GT}$ 的一个含噪实例。由于损失函数驱动网络去拟合 $Y_{HQ}$ 中的随机噪声，网络学到的映射 $f_\theta$ 必然会收敛到一个"平均"的、模糊的结果，而非清晰的 $X_{GT}$。从优化的角度看，$E[f_\theta(Y_{LQ})] \neq X_{GT}$，网络找到的是一个在LQ输入和HQ目标之间"折衷"的解，这解释了为什么传统方法得到的图像往往显得过于平滑。

此外，由于一个 $Y_{LQ}$ 实例可以由一片围绕 $\alpha X_{GT}$ 的 $Y_{HQ}$ 实例生成，反之亦然，这使得 LQ 到 HQ 的映射是"一对多"的，直接监督学习本质上是在求解一个不适定问题（ill-posed problem）。

### 3.2. 方案：基于基底信号估计的稳定监督

为了克服上述缺陷，我们不应将网络"推向"充满噪声的 $Y_{HQ}$，而应将其"拉向"更稳定的 $X_{GT}$。然而 $X_{GT}$ 是未知的。我们的核心思想是：**利用 $Y_{HQ}$ 自身的信息，先获得一个关于 $X_{GT}$ 的高质量估计 $\hat{X}_{GT}$，然后用这个稳定的估计来监督网络训练。**

我们将此过程分为两步：

**第一步：生成稳定的训练目标。** 我们采用一个强大的（非深度学习）自监督去噪算子 $\mathcal{D}$ 来处理 $Y_{HQ}$，以得到 $X_{GT}$ 的一个初始估计 $\hat{X}_{GT}$。
$$ \hat{X}_{GT} = \mathcal{D}(Y_{HQ}) $$
考虑到泊松噪声的信号依赖性，我们首先使用方差稳定变换（Variance-Stabilizing Transformation, VST），如Anscombe变换，将泊松噪声近似转化为高斯噪声，然后再应用诸如BM3D这类先进的去噪算法，最后再进行逆变换。这一步骤的关键在于，$\mathcal{D}$ 的选择是灵活的，任何先进的自监督或无监督去噪算法都可以在此应用，理论上 $\mathcal{D}$ 越强，$\hat{X}_{GT}$ 就越接近 $X_{GT}$。

**第二步：使用新目标进行网络训练。** 我们使用这个更可靠的 $\hat{X}_{GT}$ 作为监督信号，训练去噪网络 $f_\theta$。损失函数变为：
$$ \mathcal{L}_{new}(\theta) = ||f_\theta(Y_{LQ}) - \hat{X}_{GT}||_p^p $$
通过这种方式，我们将原始的"噪声到噪声"的学习任务，转化为了一个"噪声到准无噪声"的、更适定的学习任务。网络 $f_\theta$ 的优化目标不再是拟合随机噪声，而是恢复出图像的结构和细节。这种方法将不确定性从监督目标中剥离，使得网络可以专注于学习从严重降质的 $Y_{LQ}$ 到清晰的 $X_{GT}$ 的映射。这个过程并非简单的"先去噪再训练"，而是重塑了监督学习的目标，使其在数学上更合理、在物理上更接近真实。

## 4. 技术路径二：新型评估体系构建与验证

本方案的第二个核心，是构建一套科学的评估体系，以取代不适用的传统指标。

### 4.1. 统计一致性指标：泊松对数似然（PLL）

为了从根本上评估模型输出的质量，我们需要一个能够衡量其与原始数据生成过程是否"兼容"的指标。泊松对数似然（Poisson Log-Likelihood, PLL）正是为此目的而设计的。

**定义**：给定一个模型的输出 $\hat{X}_{GT}$（我们将其理解为对真实泊松分布均值 $X_{GT}$ 的估计），以及一个观测到的高计数图像 $Y_{HQ}$，PLL分数旨在量化"在假定基底信号为 $\hat{X}_{GT}$ 的情况下，我们观测到 $Y_{HQ}$ 的可能性有多大"。

对于图像中的每一个像素 $(i, j)$，其似然函数为泊松概率质量函数：
$$ P(Y_{HQ}^{(i,j)} | \hat{X}_{GT}^{(i,j)}) = \frac{(\hat{X}_{GT}^{(i,j)})^{Y_{HQ}^{(i,j)}} e^{-\hat{X}_{GT}^{(i,j)}}}{Y_{HQ}^{(i,j)}!} $$
由于直接计算所有像素概率的乘积会导致数值下溢，我们计算其对数似然之和（或平均值）：
$$
\begin{aligned}
\mathcal{L}_{PLL}(\hat{X}_{GT} | Y_{HQ}) &= \frac{1}{N} \sum_{i,j} \log P(Y_{HQ}^{(i,j)} | \hat{X}_{GT}^{(i,j)}) \\
&= \frac{1}{N} \sum_{i,j} \left( Y_{HQ}^{(i,j)} \log(\hat{X}_{GT}^{(i,j)}) - \hat{X}_{GT}^{(i,j)} - \log(Y_{HQ}^{(i,j)}!) \right)
\end{aligned}
$$
其中 $N$ 是像素总数。这个分数越高，代表模型输出 $\hat{X}_{GT}$ 作为 $Y_{HQ}$ 的基底信号的解释就越合理。

**有效性辨析**：一个潜在的疑问是：当模型输出 $\hat{X}_{GT} = Y_{HQ}$ 时，PLL分数会达到最大值，这是否意味着PLL指标在鼓励网络复制噪声？

这里的关键在于要分清**理论上的最大值**和**在去噪任务中的实际表现**：

1.  **模型的本质是去噪**：一个去噪网络 $f_\theta$ 的输出 $\hat{X}_{GT}$ 必然是平滑的，其熵远低于含噪的 $Y_{HQ}$。因此，模型输出**永远不可能**等于 $Y_{HQ}$。

2.  **比较的相对性**：我们使用PLL，不是要让某个模型达到理论最大值，而是在**不同模型的输出之间进行比较**。一个更接近真实GT的输出，能更好地"解释"$Y_{HQ}$ 中的合法计数波动，从而获得更高的PLL分数。

**结论**：PLL分数奖励那些能够准确预测光子真实通量，同时又不过度平滑，能够合理解释观测数据中统计涨落的模型。它是一个衡量统计一致性的强大工具。

### 4.2. 感知质量指标：含噪LPIPS评估方法

虽然PLL在统计上非常稳健，但它不一定完全等同于人类视觉或医生的诊断观感。LPIPS这类基于深度特征的感知度量在这方面表现出色。为了能在没有GT的临床场景下有信心地使用它，我们提出一个**含噪LPIPS评估方法**。

**方法提出的动机**：从前面的实验结果可以看出，当我们比较模型输出与高计数图像时，传统指标（PSNR/SSIM）可能显示某些方法表现更好，但这种"更好"**并不意味着模型输出更接近真正的GT**。这是因为：

1. **PSNR和SSIM不适合含噪图像间的比较**：这些指标的根本问题在于，即使是从同一个GT采样出来的两个图像，它们之间的PSNR和SSIM值也会出现很大的变化。这是因为泊松噪声的随机性导致每次采样都会产生不同的噪声模式。因此，PSNR和SSIM只适合用于"一个带噪图像与无噪GT"的对比，而不适合用于"两个带噪图像"之间的评价。在SPECT去噪任务中，我们比较的是模型输出（含有残留噪声）与高计数图像（同样含有噪声），这种比较天然地不适合使用PSNR和SSIM。

2. **LPIPS的噪声水平匹配要求**：虽然LPIPS作为感知度量具有一定的噪声鲁棒性，但它仍然具有**噪声水平匹配性**的特点。我们通过理论验证实验发现：从同一个GT采样出不同噪声水平的图像（模拟不同扫描时间），与标准扫描图像进行LPIPS计算时，结果显示**只有当噪声水平一致时，LPIPS值才达到最小**。这表明，尽管这些图像都来自同一个GT，但LPIPS更倾向于认为噪声水平相近的图像更相似。

3. **传统评估的系统性偏差**：基于上述两点，当我们直接比较模型输出与高计数图像时，传统指标会产生系统性偏差——它们更多地反映了噪声模式的匹配程度，而非真实的信号恢复质量。

**含噪LPIPS方法的理论基础**：正是基于对LPIPS噪声匹配性的深入理解，我们设计了含噪LPIPS评估方法。其核心思想是：**通过对模型输出进行泊松采样（相当于加噪），将其恢复到与原始高计数图像相同的噪声水平，然后再计算LPIPS**。

这样做的好处是：
- **消除噪声水平差异的影响**：采样后的模型输出与原始高计数图像具有相同的噪声统计特性
- **突出信号质量差异**：在相同噪声水平下，LPIPS的差异主要反映底层信号（即GT）的接近程度
- **物理过程一致性**：采样过程模拟了真实的SPECT成像物理过程

因此，在这种"噪声水平匹配"的条件下，**含噪LPIPS值越小，说明模型预测的GT越接近真实GT**。

**验证实验设计**：
基于上述理论基础，我们设计了一个验证实验来证明含噪LPIPS方法的有效性。此验证过程在有GT的**仿真数据集**上进行，目的是建立"含噪LPIPS"与"真实GT相似度"之间的可靠关联。

我们使用前述构造的XCAT仿真数据集，它具有真实的GT和符合临床统计特性的HQ图像，为验证实验提供了理想的测试平台。

1.  **训练多个模型**：使用仿真数据，训练一系列不同架构、不同超参数或不同训练策略的去噪模型 $\{f_1, f_2, ..., f_m\}$。

2.  **计算金标准分数**：对于每个模型 $f_k$，输入低计数仿真图像 $Y_{LQ}^{sim}$，得到去噪输出 $\hat{X}_{GT,k}^{sim} = f_k(Y_{LQ}^{sim})$。计算它与真实GT $X_{GT}^{sim}$ 之间的LPIPS分数，我们称之为"金标准LPIPS"。
    $$ LPIPS_{gold}^{(k)} = \text{LPIPS}( \hat{X}_{GT,k}^{sim}, X_{GT}^{sim} ) $$

3.  **计算含噪LPIPS分数**：对每个模型的输出 $\hat{X}_{GT,k}^{sim}$ 进行一次泊松采样，**将其恢复到与原始高计数数据相同的噪声水平**，得到 $\hat{Y}_{HQ,k}^{sim} \sim \text{Poisson}(\hat{X}_{GT,k}^{sim})$。然后，计算这个采样结果与原始高计数仿真数据 $Y_{HQ}^{sim}$ 之间的LPIPS分数。
    $$ LPIPS_{noisy}^{(k)} = \text{LPIPS}( \hat{Y}_{HQ,k}^{sim}, Y_{HQ}^{sim} ) $$

4.  **相关性分析**：绘制散点图，其中X轴为 $LPIPS_{gold}$，Y轴为 $LPIPS_{noisy}$。计算这两组分数之间的皮尔逊相关系数或斯皮尔曼等级相关系数。

**预期结果与理论验证**：如果散点图显示出强烈的线性或单调关系（例如，相关系数 > 0.9），这就证明了：
- **含噪LPIPS的有效性**：在相同噪声水平下，LPIPS能够正确反映模型输出与真实GT的接近程度
- **临床应用的可靠性**：我们可以在无GT的临床数据中，通过含噪LPIPS安全地评估和比较不同的去噪算法
- **理论框架的正确性**：验证了我们关于LPIPS噪声匹配性的理论分析

这个验证过程本质上是在证明：**当我们消除了噪声水平差异的干扰后，LPIPS能够成为评估信号恢复质量的可靠工具**。

## 5. 备选方案与未来探索

本方案的框架具有良好的可扩展性，为未来的深入研究提供了多个方向。

### 5.1. 更优的端到端方案：PLL作为损失函数

"稳定监督"路径在工程上清晰有效，但一个更优雅、更具理论深度的替代方案是**直接将泊松对数似然（PLL）用作损失函数**，构建一个端到端的最大似然估计框架。
$$
\begin{aligned}
\mathcal{L}_{PLL\_loss}(\theta) &= - \mathcal{L}_{PLL}(f_\theta(Y_{LQ}) | Y_{HQ}) \\
&= - \frac{1}{N} \sum_{i,j} \left( Y_{HQ}^{(i,j)} \log(f_\theta(Y_{LQ})^{(i,j)}) - f_\theta(Y_{LQ})^{(i,j)}) \right)
\end{aligned}
$$
（注意：在优化时，与 $\theta$ 无关的 $\log(Y_{HQ}!)$ 项可以被省略。）

**两种路径的比较**：
*   **稳定监督路径（本文主张）**：
    *   **优点**：实现简单，物理意义明确，改动成本低。
    *   **创新性**：更偏向于一个巧妙的工程和思想上的革新。
*   **PLL损失函数路径**：
    *   **优点**：理论上更根本和优雅，数学一致性强。
    *   **创新性**：范式级别的创新，直接对噪声分布建模，更具冲击顶级会议的潜力。

我们建议，可以将"稳定监督"路径作为有力且可靠的基线，同时将"PLL损失"路径作为更进一步的探索进行对比，这将极大提升研究的深度和影响力。

### 5.2. 技术栈升级与扩展

1.  **基底信号估计算子 $\mathcal{D}$ 的选择**：在"稳定监督"路径中，可将BM3D替换为Noise2Noise, Noise2Self等更先进的自监督去噪方法，以获得更精确的 $\hat{X}_{GT}$。

2.  **去噪网络主干 $f_\theta$ 的升级**：本方案的方法论与具体网络架构解耦。可将U-Net等替换为SwinIR、Restormer等基于Transformer的先进架构，以追求更优性能。

## 6. 总结与预期贡献

本研究方案针对当前深度学习在SPECT图像去噪应用中的核心痛点——不合理的训练目标和不恰当的评估指标——提出了一套完整的解决方案。

## 7. 实验验证与结果分析

### 7.1. 实验设置

我们首先在仿真数据集上进行了8倍快速扫描的降噪实验，以验证所提出的方法。具体设置如下：

**仿真数据集构造**：
为了确保实验的真实性和临床相关性，我们构造了一个高质量的仿真数据集：

1. **体模生成**：使用XCAT（Extended Cardiac-Torso phantom）软件模拟100例不同病人的体模，涵盖了不同的解剖结构和病理特征，确保数据的多样性和代表性。

2. **设备响应模拟**：对生成的体模添加高斯模糊，以模拟真实SPECT设备的空间分辨率限制，得到理想的无噪声图像作为Ground Truth (GT)。

3. **高计数图像生成**：对GT进行泊松采样，模拟真实的光子计数过程，生成高计数图像（HQ）。为保证临床相关性，我们将总计数归一化到临床骨平片扫描的典型水平，即130-150万计数。

4. **低计数图像生成**：通过对HQ进行下采样（8倍快速扫描），生成对应的低计数图像（LQ），模拟临床快速扫描场景。

这种构造方法确保了：
- **物理真实性**：完全遵循SPECT成像的物理过程
- **临床相关性**：计数水平与实际临床应用一致
- **统计准确性**：泊松噪声特性与真实数据匹配
- **可控性**：拥有真实的GT用于算法验证

**网络架构**：
- DRUNet：作为baseline的经典去噪网络
- RRDBNet：具有残差密集块结构的网络
- SwinIR：基于Swin Transformer的先进网络架构

**训练策略**：
- 对比了两种训练目标：
  1. 直接使用HQ图像作为目标（传统方法）
  2. 使用BM3D去噪后的HQ图像作为目标（本文提出的稳定监督方法）
- 损失函数：采用Charbonnier损失函数
  $$ \mathcal{L}_{char}(x, y) = \sqrt{(x-y)^2 + \epsilon^2} $$
  其中$\epsilon$是一个小的常数（通常取$10^{-3}$）。这种损失函数相比传统的$L_1$或$L_2$损失，对异常值更加鲁棒，能够提供更稳定的训练过程。

### 7.2. 实验结果

#### 7.2.1. 与Ground Truth的对比

首先，我们用仿真数据（有GT）验证不同方法的效果：

| 模型 | 训练目标 | PSNR↑ | SSIM↑ | LPIPS↓ |
|------|----------|--------|--------|---------|
| **SwinIR** | **自监督去噪目标** | **42.98** | **0.99072** | **0.0314** |
| RRDBNet | 自监督去噪目标 | 41.97 | 0.98924 | 0.0352 |
| DRUNet | 高计数图像 | 38.53 | 0.9458 | 0.2469 |
| RRDBNet | 高计数图像 | 37.97 | 0.9432 | 0.2489 |

这个表格告诉我们：使用自监督去噪目标训练的模型，在所有指标上都表现更好，其中SwinIR取得了最佳效果。

#### 7.2.2. 与原始高计数图像的对比

**重要说明**：大多数相关研究使用PSNR、SSIM和LPIPS作为评估指标，但在SPECT去噪任务中，这些指标存在根本性问题：

1. **PSNR和SSIM的局限性**：这些指标假设图像是确定性的，适合评估确定性图像处理任务（如JPEG压缩去噪）。但SPECT成像是随机过程，即使是"高计数图像"本身也包含噪声，用确定性指标评估随机成像任务会产生误导。

2. **LPIPS的噪声敏感性**：虽然LPIPS在很多任务中表现出色，但它对噪声敏感，在评估含噪图像时可能不够稳健。

因此，我们引入**PLL作为主要评估指标**，它专门设计用于评估模型输出与原始数据生成过程的一致性：

| 模型 | 训练目标 | PSNR↑ | SSIM↑ | LPIPS↓ | PLL↑ |
|------|----------|--------|--------|---------|-------|
| **SwinIR** | **自监督去噪目标** | 32.722 | 0.82188 | 0.33208 | **-1.22296** |
| RRDBNet | 自监督去噪目标 | 32.674 | 0.8214 | 0.33213 | -1.22377 |
| DRUNet | 高计数图像 | **33.254** | **0.8498** | **0.1836** | -1.27343 |
| RRDBNet | 高计数图像 | 33.1652 | 0.84855 | 0.18308 | -1.26332 |

**结果分析的关键洞察**：
1. **传统指标的误导性**：传统指标（PSNR/SSIM/LPIPS）显示直接以高计数图像为目标的方法表现更好，但这种"更好"是虚假的——它们只是更好地拟合了高计数图像中的噪声，而非更接近真正的GT
2. **PLL指标的正确性**：PLL指标显示相反的结论——自监督去噪目标的方法实际上更优，这与GT对比实验的结果一致，证明了PLL能够正确反映模型的真实性能
3. **评估体系革新的必要性**：这个矛盾恰好证明了我们的核心观点：传统指标在随机成像任务中不仅不准确，还会产生系统性误导，因此必须建立新的评估体系

**深层含义**：这个实验揭示了一个重要事实——**在SPECT这类随机成像任务中，与含噪参考图像的相似度高，并不等同于与真实信号的相似度高**。这正是为什么我们需要设计含噪LPIPS等新评估方法的根本原因。

#### 7.2.3. 含噪LPIPS验证

为了验证我们的方法在临床实践中的有效性，我们设计了一个模拟临床环境的评估方案：

| 模型 | 训练目标 | 含噪LPIPS↓ |
|------|----------|----------------|
| SwinIR | 自监督去噪目标 | **0.11489** |
| RRDBNet | 自监督去噪目标 | 0.11604 |
| DRUNet | 高计数图像 | 0.12343 |
| RRDBNet | 高计数图像 | 0.12452 |

**实验设计的核心逻辑**：这个评估方案的关键在于**创造公平的比较条件**。我们对每个模型的输出进行泊松采样，使其与原始高计数图像具有相同的噪声水平，从而消除了噪声水平差异对LPIPS评估的影响。

**结果验证了理论预期**：
1. **噪声水平匹配的有效性**：通过采样操作，我们成功地让所有比较对象处于相同的噪声水平，此时LPIPS的差异主要反映的是底层信号质量的差异
2. **与GT评估的一致性**：含噪LPIPS的排序与第7.2.1节中GT对比的结果完全一致，这验证了我们理论分析的正确性——在消除噪声水平干扰后，LPIPS能够正确反映模型输出与真实GT的接近程度
3. **自监督去噪目标的优越性**：使用自监督去噪目标的方法在含噪LPIPS评估中表现更好，这与PLL评估结果一致，进一步证明了我们提出的"稳定监督"范式的有效性

**临床应用意义**：这些结果证实了含噪LPIPS方法可以作为无GT场景下的可靠评估工具。在真实的临床环境中，我们只需要：
1. 对待评估的模型输出进行泊松采样
2. 计算采样结果与临床高计数图像的LPIPS
3. 根据含噪LPIPS值判断模型性能

这为临床SPECT去噪算法的评估和选择提供了科学依据。

### 7.3. 结果分析

综合以上实验结果，我们可以得出以下结论：

1. **训练目标的重要性**：使用自监督去噪目标的方法在所有评估指标上都显著优于传统方法，这验证了我们提出的"稳定监督"范式的有效性。

2. **网络架构的影响**：SwinIR网络在自监督去噪目标下取得了最佳性能，这表明先进的网络架构与合适的训练目标相结合可以带来更好的结果。

3. **评估指标的选择**：实验结果清晰地展示了为什么传统指标（PSNR/SSIM）可能产生误导性结论，而PLL和含噪LPIPS能够更好地反映模型的实际性能。

4. **临床可用性的验证**：含噪LPIPS评估结果与GT评估结果的一致性，证明了我们提出的评估方法在临床实践中的可行性。

这些实验结果不仅验证了本文提出的方法，也为未来的研究提供了重要的参考。

**预期贡献**：
1.  **方法学贡献**：提出"稳定监督"范式，引导网络学习更接近物理真实的映射，有望获得细节更丰富、伪影更少的去噪结果。

2.  **评估体系贡献**：建立一套包含PLL和已验证的含噪LPIPS评估方法的评估体系，为在无GT的临床环境中科学地评估和比较随机图像处理算法，提供重要的思路和工具。

我们相信，这套"重塑目标，重建评估"的范式，不仅为提升SPECT图像质量提供了有效的技术路径，也为未来该领域的研究提供了坚实的方法论参考。
